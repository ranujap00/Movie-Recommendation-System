{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movie_data_with_urls.csv')\n",
    "ratings = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movList = list(movies['genres'])\n",
    "sp_list = []\n",
    "\n",
    "for mov in movList:\n",
    "    sp_list.append(mov.split('|'))\n",
    "\n",
    "movies['genres'] = sp_list\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(lambda genre_list: [genre.lower() for genre in genre_list])\n",
    "movies['title'] = movies['title'].str.lower()\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(movies.head(), ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_ratings = movies.merge(ratings, how='inner', on='movieId')\n",
    "mov_ratings.drop('timestamp', axis=1, inplace=True)\n",
    "mov_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_ratings[mov_ratings['title'] == 'Cocoon (1985)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = mov_ratings[['movieId', 'title', 'genres', 'Poster_URL']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove square brackets\n",
    "new_df['genres'] = new_df['genres'].apply(lambda x: ' '.join(x))\n",
    "new_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.reset_index()\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform given text into a vector on the basis of frequency count\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=23, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(new_df['genres']).toarray()\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "pt = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(pt.stem(i))\n",
    "    \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['genres'] = new_df['genres'].apply(stem)\n",
    "new_df['genres'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array to a pickle file\n",
    "with open('./PKL_Files/stemmed_df_content_based', 'wb') as file:\n",
    "    pickle.dump(new_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array to a pickle file\n",
    "with open('./PKL_Files/similarity_content_based', 'wb') as file:\n",
    "    pickle.dump(similarity, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    # load files\n",
    "    # Load the array from the pickle file\n",
    "    with open('./PKL_Files/stemmed_df_content_based', 'rb') as file:\n",
    "        new_df = pickle.load(file)\n",
    "\n",
    "        # Load the array from the pickle file\n",
    "    with open('./PKL_Files/similarity_content_based', 'rb') as file:\n",
    "        similarity = pickle.load(file)\n",
    "\n",
    "    mov_list = []\n",
    "    movie_index = new_df[new_df['title'] == movie].index[0]\n",
    "    distances = similarity[movie_index]\n",
    "    movie_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x:x[1])[1:6]\n",
    "\n",
    "    for i in movie_list:\n",
    "        d = dict()\n",
    "        d['title'] = new_df.iloc[i[0]].title\n",
    "        d['url'] = new_df.iloc[i[0]].Poster_URL\n",
    "        mov_list.append(d)\n",
    "    \n",
    "    return mov_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_mov_list = recommend('toy story (1995)')\n",
    "for m in recommended_mov_list:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_ratings[mov_ratings['title'] == 'nothing in common (1986)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove square brackets\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "mov_ratings['genres'] = mov_ratings['genres'].apply(lambda x: ' '.join(x))\n",
    "mov_ratings.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array to a pickle file\n",
    "with open('./PKL_Files/movie_rating_collaborative', 'wb') as file:\n",
    "    pickle.dump(mov_ratings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users who have given more than 100 ratings are considered\n",
    "\n",
    "x = mov_ratings.groupby('userId').count()['rating'] > 100\n",
    "users = x[x].index\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rating = mov_ratings[mov_ratings['userId'].isin(users)]\n",
    "filtered_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies with more than 50 ratings\n",
    "y = filtered_rating.groupby('title').count() > 50\n",
    "famous_movies = y[y].index\n",
    "famous_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ratings = filtered_rating[filtered_rating['title'].isin(famous_movies)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = final_ratings.pivot_table(index='title',columns='userId',values='rating')\n",
    "pt.fillna(0,inplace=True)\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array to a pickle file\n",
    "with open('./PKL_Files/pivot_table_collaborative', 'wb') as file:\n",
    "    pickle.dump(pt, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = cosine_similarity(pt)\n",
    "similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array to a pickle file\n",
    "with open('./PKL_Files/similarity_scores_collaborative', 'wb') as file:\n",
    "    pickle.dump(similarity_scores, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_recommend(movie_name):\n",
    "    # Load files\n",
    "    with open('./PKL_Files/movie_rating_collaborative', 'rb') as file:\n",
    "        mov_ratings = pickle.load(file)\n",
    "\n",
    "    with open('./PKL_Files/similarity_scores_collaborative', 'rb') as file:\n",
    "        similarity_scores = pickle.load(file)\n",
    "\n",
    "    with open('./PKL_Files/pivot_table_collaborative', 'rb') as file:\n",
    "        pt = pickle.load(file)\n",
    "\n",
    "    # index fetch\n",
    "    index = np.where(pt.index==movie_name)[0][0]\n",
    "\n",
    "    similar_items = sorted(list(enumerate(similarity_scores[index])),key=lambda x:x[1],reverse=True)[1:5]\n",
    "    # simillar items from 1 to 4\n",
    "    \n",
    "    data = []\n",
    "    for i in similar_items:\n",
    "        item = []\n",
    "        d = dict()\n",
    "        temp_df = mov_ratings[mov_ratings['title'] == pt.index[i[0]]]\n",
    "        item.extend(list(temp_df.drop_duplicates('title')['title'].values))\n",
    "\n",
    "        # urls = temp_df['Poster_URL'].str.replace(r'\\d+', '', regex=True) # to remove the index value before the RL\n",
    "\n",
    "        d['title'] = item[0]\n",
    "        d['url'] = temp_df['Poster_URL'].values.tolist()[0]\n",
    "        data.append(d)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collaborative_recommend('zulu (1964)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
